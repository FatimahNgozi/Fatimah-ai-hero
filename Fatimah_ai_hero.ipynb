{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb20910b-bbf5-41bf-9a6a-5d732dff4f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "import frontmatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10397b78-59ae-445d-9a35-5034d8f9985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "---\n",
    "title: \"Getting Started with AI\"\n",
    "author: \"Fatimah Adeniyi\"\n",
    "date: \"2025-09-24\"\n",
    "tags: [\"ai\", \"machine-learning\", \"tutorial\"]\n",
    "difficulty: \"beginner\"\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d617aa-2544-4e62-b6a3-795766c1ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import frontmatter\n",
    "\n",
    "with open('example.md', 'r', encoding='utf-8') as f:\n",
    "    post = frontmatter.load(f)\n",
    "\n",
    "# Access metadata\n",
    "print(post.metadata['title'])  # \"Getting Started with AI\"\n",
    "print(post.metadata['tags'])   # [\"ai\", \"machine-learning\", \"tutorial\"]\n",
    "\n",
    "# Access content\n",
    "print(post.content)  # The markdown content without frontmatter\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76533005-64fd-4a6d-9c18-3a78656220dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://codeload.github.com/FatimahNgozi/AWS-S3-static-website-hostiiing/zip/refs/heads/main'\n",
    "resp = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3eb39b8-90df-4df2-b56f-fea86120d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "repository_data = []\n",
    "#Create a ZipFile object from the downloaded content\n",
    "zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "for file_info in zf.infolist():\n",
    "    filename = file_info.filename.lower()\n",
    "\n",
    "    # Only process markdown files\n",
    "    if not filename.endswith('.md'):\n",
    "        continue\n",
    "    # Read and parse each file\n",
    "    with zf.open(file_info) as f_in:\n",
    "        content = f_in.read()\n",
    "        post = frontmatter.loads(content)\n",
    "        data = post.to_dict()\n",
    "        data['filename'] = filename\n",
    "        repository_data.append(data)\n",
    "\n",
    "zf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8290bb9c-ab66-40bd-9c87-24e8ca1ab974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': '# AWS-S3-static-website-hosting\\n\\nThis repository documents my learning with static website hosting on Amazon S3.\\nI have my step-by-step guide on exactly how i did it\\nTechnologies used includes: Amazon S3, HTML, CSS & JavaScript\\n\\n## Getting Started\\nAfter all the necessary contents such as text, images and other media content has been gathered, we move straight to S3 bucket setup.\\nAmazon S3 Bucket Setup:\\nA new Amazon S3 bucket is created and configured specifically for hosting your static website(in my case MercyReads)\\n\\n![image](https://github.com/user-attachments/assets/ab3a4ac2-1149-4705-b0d7-13fbd5831c5f)\\n\\nChoose Properties and scroll down to the option Static website hosting and click on Edit button to enable the feature.\\n\\n![image](https://github.com/user-attachments/assets/8904e5e2-592e-47ec-905a-1dc1bd8a1703)\\n\\n![image](https://github.com/user-attachments/assets/4b020080-d94e-463c-ab1b-79af3df5778f)\\n\\n![image](https://github.com/user-attachments/assets/3e5299fc-9ed6-48d4-9aea-c295a5733dd8)\\n\\n![image](https://github.com/user-attachments/assets/419ff133-1e01-4b3c-bc1e-3a72a6987804)\\n\\nIn the index document part, put your index.html in there and put 404.html in the error document\\n\\nSave changes to get a success edit message\\n\\nUpon scrolling down to the Static website hosting section you will find the link of your bucket, click on it to open the link\\n\\nYou will find an error message\\n\\nWhen you create any bucket, by default it is not publicly accessible. To actually make the bucket accessible, scroll back up, go to the Block public access (bucket settings), click on the edit button to untick/disable(off) the Block all public access button and save changes and enter confirm in the field provided to confirm the changes.\\n\\nYou will get a success message\\n\\nOn clicking on the bucket link again, you will get an error message still, so here is what to do next\\n\\nThe good part of S3 is that it gives multiple level of blocking to ensure your bucket is safe at bucket level and account level.\\n\\nNow let\\'s edit the bucket policy so that the bucket is accessible. Under Permissions, scroll down to the Bucket policy and click on the Edit button\\n\\n{\\n  \"Version\": \"2012-10-17\",\\n  \"Statement\": [\\n    {\\n      \"Sid\": \"PublicReadGetObject\",\\n      \"Effect\": \"Allow\",\\n      \"Principal\": \"*\",\\n      \"Action\": [\\n        \"s3:GetObject\"\\n      ],\\n      \"Resource\": [\\n        \"arn:aws:s3:::Bucket-Name/*\"\\n      ]\\n    }\\n  ]\\n}\\n\\nCopy and paste the above json file in the section. Be sure to change the Bucket-Name with your own bucket name and save changes.\\n\\nNow you will find that your S3 bucket is Publicly accessible\\n\\nNow Click on Properties, scroll down then click on the S3 bucket link that is in Static website hosting section. It should display a 404 not found error and that is because the index.html file hasn\\'t been uploaded (i.e no object yet in the bucket).\\n\\nNow, add files to the S3 bucket created and also make and error file so that in case the user could not access the files, it would get a better error message instead of 404 not found.\\n\\nOpen the terminal and create a 404.html file\\n\\nYou will find that there is a 404.html created. Now copy this 404.html file to your S3 bucket using the command given below (aws s3 cp 404.html s3://bucket-name)\\n\\nOn refreshing the browser you will find the customized message instead of 404 Not found\\n\\nIn a better way to understand, this link displays error page because there is no other files available in the bucket for the user to access.\\n\\nNow we will have to sync other files. You can use the (aws s3 sync\\xa0. s3://bucket-name)\\n\\nNow refresh your bucket on AWS management console and you will find other files there.\\n\\nNow refresh your browser and you will see the Static website is ready\\n\\nConsider Monitoring and Maintenance\\n\\nImplementing monitoring tools is essential for tracking website performance, availability and identifying potential errors.\\n\\nAWS provides various services and integrations that can help you achieve comprehensive monitoring. Amazon CloudFront and AWS WAF Logs can be of good help.\\n\\nIf you use Amazon CloudFront with AWS WAF, monitor CloudFront access logs and WAF logs to identify potential security threats and track the performance of your CDN.\\n\\nConfigure CloudFront by navigating to cloudFront from the AWS console and click on create distribution.\\n\\nUnder Origin Options, Origin domain should be given, therefore you should copy and paste the link of your S3 bucket from the browser to the Origin domain. So any requests that happens will be directed to the link in the browser\\n\\nClick on Next and enable security protection at the Web Application Firewall (WAF)\\n\\nCreate Cache Policy for your distribution by clicking on create cache policy radio button.\\n\\nThen create the distribution\\n\\nStatic Website Hosting is live!', 'filename': 'aws-s3-static-website-hostiiing-main/readme.md'}]\n"
     ]
    }
   ],
   "source": [
    "print(repository_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebcc13ed-6fe6-4696-9527-3c06a66ddc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_repo_data(repo_owner, repo_name):\n",
    "    \"\"\"\n",
    "    Download and parse all markdown files from a GitHub repository.\n",
    "    \n",
    "    Args:\n",
    "        repo_owner: GitHub username or organization\n",
    "        repo_name: Repository name\n",
    "    \n",
    "    Returns:\n",
    "        List of dictionaries containing file content and metadata\n",
    "    \"\"\"\n",
    "    prefix = 'https://codeload.github.com' \n",
    "    url = f'{prefix}/{repo_owner}/{repo_name}/zip/refs/heads/main'\n",
    "    resp = requests.get(url)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        raise Exception(f\"Failed to download repository: {resp.status_code}\")\n",
    "\n",
    "    repository_data = []\n",
    "    zf = zipfile.ZipFile(io.BytesIO(resp.content))\n",
    "    \n",
    "    for file_info in zf.infolist():\n",
    "        filename = file_info.filename\n",
    "        filename_lower = filename.lower()\n",
    "\n",
    "        if not (filename_lower.endswith('.md') \n",
    "            or filename_lower.endswith('.mdx')):\n",
    "            continue\n",
    "        try:\n",
    "            with zf.open(file_info) as f_in:\n",
    "                content = f_in.read().decode('utf-8', errors='ignore')\n",
    "                post = frontmatter.loads(content)\n",
    "                data = post.to_dict()\n",
    "                data['filename'] = filename\n",
    "                repository_data.append(data)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    zf.close()\n",
    "    return repository_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba2732bf-0d2c-4456-acdb-e546f40ceacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "myrepo_aws = read_repo_data('FatimahNgozi', 'AWS-S3-static-website-hostiiing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1415b8f0-d1c5-401e-ab88-e9c8010c60e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Documents: 1\n"
     ]
    }
   ],
   "source": [
    "print(f\"AWS Documents: {len(myrepo_aws)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c370b9-2e28-4a60-8bcf-f467410e87ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
